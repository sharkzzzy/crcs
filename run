import os
import torch
from diffusers import StableDiffusionXLPipeline
from pipeline_carc import CARCPipeline, save_output

def main():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model_id = "stabilityai/stable-diffusion-xl-base-1.0"
    print(f"ğŸš€ Loading SDXL Base in FP32 on {device}...")

    try:
        base_pipe = StableDiffusionXLPipeline.from_pretrained(
            model_id,
            use_safetensors=True,
        ).to(device)

        # 1. å¼ºåˆ¶å…¨ FP32 (æœ€ç¨³)
        base_pipe.vae.to(dtype=torch.float32)
        base_pipe.text_encoder_2.to(dtype=torch.float32)
        base_pipe.unet.to(dtype=torch.float32)

        # 2. æ˜¾å­˜ä¼˜åŒ– (å¯é€‰ï¼Œæ ¹æ®æ˜¾å­˜æƒ…å†µ)
        print("ğŸ”§ Enabling VAE Tiling & Slicing...")
        base_pipe.enable_vae_tiling()
        base_pipe.enable_vae_slicing()
        
    except Exception as e:
        print(f"Error loading model: {e}")
        exit(1)

    # ==========================================================================
    # CARC åˆå§‹åŒ–
    # ==========================================================================
    # æ³¨å…¥å±‚ï¼šåŒ…å«ä½/ä¸­å±‚ï¼Œé¿å¼€æé«˜åˆ†å±‚ (up.1/up.2) é˜²æ­¢è¯­ä¹‰é”™ä¹±
    # up_blocks.0 æ˜¯ 32x32ï¼Œæ˜¯æ ¸å¿ƒå±‚ï¼Œå¿…é¡»ä¿ç•™
    inject_patterns = ["down_blocks.2", "mid_block", "up_blocks.0"]
    
    alpha_config = {
        "construct_phase": (0.0, 0.35, 0.15),
        "texture_phase":   (0.35, 0.75, 0.6), # ä¸­æ®µå¼ºåº¦é€‚ä¸­
        "refine_phase":    (0.75, 1.0, 0.45),
    }

    carc_pipe = CARCPipeline(
        base_pipe=base_pipe,
        alpha_cfg=alpha_config,
        inject_layer_patterns=inject_patterns
    )

    # ==========================================================================
    # æç¤ºè¯ç­–ç•¥ (Clean Global + Strong Local)
    # ==========================================================================
    # å…¨å±€ï¼šçº¯èƒŒæ™¯ï¼Œç»å¯¹ä¸æçŒ«ç‹—ï¼Œé˜²æ­¢ç”Ÿæˆåº•å›¾æ€ªç‰©
    global_bg = "in a sunny park with green grass and trees, blurred background, cinematic lighting, 8k, photorealistic"
    global_prompt = f"A wide photo of a park scene, {global_bg}"

    subjects = [
        {
            "name": "cat",
            # å¼ºè°ƒç‹¬ç«‹æ€§
            "prompt": "a red cat sitting, full body, fluffy, sharp details, left side, clearly separated",
            "position": "left",
            "neg_target": "blue dog, blue fur",
        },
        {
            "name": "dog",
            "prompt": "a blue dog sitting, full body, sharp details, right side, clearly separated",
            "position": "right",
            "neg_target": "red cat, red fur",
        }
    ]

    # ==========================================================================
    # æ‰§è¡Œç”Ÿæˆ
    # ==========================================================================
    print("ğŸ¨ Generating image (With Cross-Attn Gating & Softmax Mask)...")
    seed = 2024

    result = carc_pipe(
        global_prompt=global_prompt,
        subjects=subjects,
        width=1024,
        height=1024,
        num_inference_steps=40,

        # å¼•å¯¼ç³»æ•°
        cfg_pos=7.5,
        cfg_neg=3.0,          

        # æ©ç ç­–ç•¥
        mask_update_interval=5, # å¼€å¯ Probe
        bg_update_interval=2,

        # Mask Manager å‚æ•° (ä¼ é€’ç»™ pipeline)
        beta=0.6,
        safety_expand=0.05,   # ä¸¥é˜²è¶Šç•Œ
        gap_ratio=0.08,       # åˆå§‹ä¸­ç¼ 8%
        bg_floor=0.05,        # èƒŒæ™¯åº•æƒé‡
        
        # èåˆç³»æ•°
        kappa=1.5,            # å¼ºåŠ›å·®åˆ†èåˆ

        seed=seed,
    )

    os.makedirs("outputs", exist_ok=True)
    save_path = f"outputs/carc_final_v11_seed{seed}.png"
    save_output(result, save_path)
    print(f"âœ… Done. Saved to: {save_path}")
    print("Expectation: Two separate animals, correct colors, unified background.")

if __name__ == "__main__":
    main()
